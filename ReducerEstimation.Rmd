---
title: "ReducerEstimation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Notebook for exploring reduction 

This notebook will explore _estimation_ in for reducer models.  For the setup and population see "ReducerNotes.Rmd".  

# SNoTE
Consider both linear mean and propensity models. Assume that $r(X)$ is also linear in $X$.
$$
\begin{align}
m_0(X) &= \mathbf{\alpha}'X \quad \text{(Expectation of control outcome)}\\
e(X) &= \mathbf{\beta}'X \quad \text{(Propensity score)}\\
d(X) &= \gamma'X \quad \text{(Deconfounding score)}
\end{align}
$$

where $\alpha$ is an $p \times m_\alpha$ matrix and $\beta$ is a $p \times m_\beta$ matrix with $m < p$.  Assume (welog?) that $\alpha$ and $\beta$ are semi-orthogonal matrices, e.g. $\alpha^T\alpha = I$.  

```{r}
logistic <- function(x) 1 / (1 + exp(-x))

## for different sample sizes from 50 to 250
bias_for_n <- c()
bias_for_n_a <- c()
bias_for_n_b <- c()
ubias_for_n <- c()
form_for_n <- c()
for(j in 1:20) {
  n <-  50 + (j-1)*100
  bias_vec_a <- bias_vec_b <- bias_vec <- c()
  raw_diff <- bias_form <- c()

    ## compute bias as average of 100 simulations
    for(i in 1:100) {
    
    p <- 12
    
    alpha <- 4*c(1, -1, 0, rep(0, p-3))/sqrt(2)
    beta <- c(1, 0, 1, rep(0, p-3))/sqrt(2)
    
    library(mvtnorm)
    library(rstiefel)
    
    #X <- rmvnorm(n, rep(0, p), diag(.5, p))
    X <- matrix(2 * runif(p*n) - 1, nc=p)
    mscale <- 5
    m <- mscale * X %*% alpha
    xb <- X %*% beta 
    escale <- log(10)
    e <- exp(escale*xb)/(1 + exp(escale*xb))
    
    ## temporary hack
    ##e[e >= 1/2] <- 0.49
    ##e[e < -1/2] <- -0.49
    ## e <- jitter(e)

    T <- rbinom(n, 1, e)
    Y0 <- rnorm(n, m, 5)
    
    ## estimates of m and e
    ## beta_hat <- coef(lm((T - 1/2) ~ X - 1))
    beta_hat <- coef(glm(T ~ X - 1))
    alpha_hat <- coef(lm(Y0[T==0] ~ X[T==0, ] - 1))
    
    cor(beta, beta_hat)
    cor(alpha, alpha_hat)
    
    ## normalize to get d(X) surface
    alpha_hat_norm <- sqrt(sum(alpha_hat^2))
    beta_hat_norm <- sqrt(sum(beta_hat^2))
    alpha_hat_normalized <- alpha_hat / alpha_hat_norm
    beta_hat_normalized <- beta_hat / beta_hat_norm
    
    # null space of alpha
    A <- diag(p) - alpha_hat_normalized %*% t(alpha_hat_normalized)
    # null space of beta
    B <- diag(p) - beta_hat_normalized %*% t(beta_hat_normalized)
    
    AnotB  <- eigen(A %*% (diag(p) - B))$vectors[, 1]
    BnotA  <- eigen(B %*% (diag(p) - A))$vectors[, 1]
    
    
    z <- cbind(AnotB, eigen(A %*% (diag(p) - AnotB %*% t(AnotB)))$vectors[, 1]) %*% c(cos(pi/4), sin(pi/4))
    w <- eigen(B %*% (diag(p) - z %*% t(z)))$vectors[, 1:(p-2)]
    
    u <- eigen(z %*% t(z) + w %*% t(w))$vectors[, 1:(p-1)]
    M <- u %*% t(u)
    
    alpha_hat %*% M %*% beta_hat
    
    ## gamma is now the eigenvector of I - M (step 4)
    eig <- eigen(diag(p) - M)
    
    g <- eig$vectors[, 1]
    
    ## step 5
    d <- Re(X %*% g)
    d_a <- X %*% alpha_hat
    d_b <- X %*% beta_hat
    
    ## check uncorrelated condition holds
    res1 <- lm(d_a ~ d-1)$residuals
    res2 <- lm(d_b ~ d-1)$residuals
    cor(res1, res2)

    lm_md <- lm(m ~ d-1)
    mr <- lm_md$residuals
    mfit <- lm_md$fitted
    #lm_ed <- lm(e ~ d-1)
    lm_ed <- loess(e ~ d-1)
    er <- lm_ed$residuals
    efit <- lm_ed$fitted
    bias_vec[i] <- mean(cov(mr, er) / (1 - efit))
    
    mr_a <- lm(m ~ d_a -1)$residuals
    #lm_ed_a <- lm(e ~ d_a-1)
    lm_ed_a <- loess(e ~ d_a-1)
    er_a <- lm_ed_a$residuals
    efit_a <- lm_ed_a$fitted
    bias_vec_a[i] <- mean(cov(mr_a, er_a) / (1 - efit_a))
    
    mr_b <- lm(m ~ d_b-1)$residuals
    #lm_ed_b <- lm(e ~ d_b-1)
    lm_ed_b <- loess(e ~ d_b-1)
    er_b <- lm_ed_b$residuals
    efit_b <- lm_ed_b$fitted
    bias_vec_b[i] <- mean(cov(mr_b, er_b) / (1 - efit_b))
    
    raw_diff[i] <- mean(Y0) - mean(Y0[T==0])
    bias_form[i] <- mean(cov(Y0, T) / (1-mean(e)))
    
  }
  bias_for_n[j] <- mean(bias_vec)  
  bias_for_n_a[j] <- mean(bias_vec_a)  
  bias_for_n_b[j] <- mean(bias_vec_b)  
  ubias_for_n[j] <- mean(raw_diff)
  form_for_n[j] <- mean(bias_form)
}
```

```{r}
unconditional_bias <- mean(as.numeric(cov(Y0, T))/(1-mean(e)))
print(unconditional_bias)
ymax = 1.1*max(c(bias_for_n, bias_for_n_b, bias_for_n_a, form_for_n))
plot(40 + (1:20)*100, bias_for_n, type="l", lwd=2, xlab="sample size", ylab="bias", ylim=c(0, ymax)) 
lines(40 + (1:20)*100, bias_for_n_b, type="l", lwd=2, xlab="sample size", ylab="bias", col="blue")
lines(40 + (1:20)*100, bias_for_n_a, type="l", lwd=2, xlab="sample size", ylab="bias", col="red") 
lines(40 + (1:20)*100, form_for_n, type="l", lwd=2, xlab="sample size", ylab="bias", lty=2)
lines(40 + (1:20)*100, ubias_for_n, type="l", lwd=2, xlab="sample size", ylab="bias", lty=3)

legend("topright", legend=c("pi/4", "pi/2 (d=e)", "0 (d=m)"), col=c("black", "blue", "red"), lty=1, lwd=2, title="Alpha angle")



mean(Y0[T==1])
mean(Y0[T==0])
```

```{r}
## Under development. Not run.

normalize <- function(x){
  x / sqrt(sum(x^2))
}

n <- length(m)
zero_cov_obj <- function(gamma, X, m, e, lambda=0.01, lambda2=0.01, justmain=FALSE){
  d <- X %*% gamma
  d <- (d - mean(d)) / sd(d)
  ef <- loess(e ~ d)
  mf <- loess(m ~ d)
  ehat <- ef$fitted
  mhat <- mf$fitted
  main <- (mean(mhat * ehat) - mean(m * e))^2
  if(justmain) return(main)
  # Zero bias condition + unit norm condition
  sqrt(main) + sqrt((sqrt(sum(gamma^2)) - 1)^2) + 
    # Modulate agreement with prog vs pscore
    - lambda * sqrt(sum(mf$residuals^2)/n) - lambda2 * sqrt(sum(ef$residuals^2)/n)
}
ghat_a <- fit_ghat(alpha, X, m, e, lambda=0, lambda2=1)

fit_ghat <- function(init, X, m, e, lambda, lambda2){
  ghat_b <- optim(init,
                  function(g) zero_cov_obj(g, X, m, e, lambda, lambda2),
                  method="L-BFGS-B", control=list(trace=1))
  ghat_b$lambda <- lambda
  ghat_b$lambda2 <- lambda2
  class(ghat_b) <- "ghat"
  ghat_b
}

#ghat_b <- fit_ghat(alpha, X, m, e, lambda=1, lambda2=0)
#ghat_c <- fit_ghat(alpha, X, m, e, lambda=0.5, lambda2=0.5)

ghat_list <- lapply(seq(0, 1, by=0.1),
                    function(l2)
                      fit_ghat(beta, X, m, e, lambda=1-l2, lambda2=l2))

report <- function(x){
  UseMethod("report", x)
}  

report.ghat <- function(ghat){
  lambda <- ghat$lambda
  lambda2 <- ghat$lambda2
  print(zero_cov_obj(ghat$par, X, m, e, lambda, lambda2, justmain=TRUE))
  print(zero_cov_obj(ghat$par, X, m, e, lambda, lambda2, justmain=FALSE))
  gpar <- ghat$par
  print(cor(X%*%gpar, m))
  print(cor(X%*%gpar, e))
  print(gpar %>% round(3))
  return(gpar)
}

lapply(ghat_list, report)

alpha %>% normalize %>% round(3)
stop()
ghat_b <- optim(beta, function(g) zero_cov_obj(g, X, m, e), method="L-BFGS-B")

ghat_a$value
ghat_b$value


#ghat_g <- optim(Re(g), function(g) zero_cov_obj(g, X, m, e), method="L-BFGS-B")
#set.seed(0)
#ghat_r <- optim(rustiefel(p, 1), function(g) zero_cov_obj(g, X, m, e), method="L-BFGS-B")
cbind(ghat_a$par %>% normalize,
      (ghat_b$par * (-1 * (ghat_a$par[1] * ghat_b$par[1] < 0))) %>% normalize,
      alpha %>% normalize,
      beta %>% normalize) %>% matplot
```

